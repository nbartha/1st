{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1kPWakJJ0QM6f0BVHSPhw4Prh-6pIL5ns",
      "authorship_tag": "ABX9TyOmFrpba0lMQ4SR17QLgZ0c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nbartha/1st/blob/main/AER850%20Project%201\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from joblib import dump\n",
        "\n",
        "\n",
        "# Step 2.1 – Load Data\n",
        "\n",
        "data_path = \"Project 1 Data.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "features = ['X', 'Y', 'Z']\n",
        "target = 'Step'\n",
        "\n",
        "print(f\"Data loaded. Shape: {df.shape}\")\n",
        "print(df.head())\n",
        "\n",
        "# Encode target for ML\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(df[target])\n",
        "X = df[features]\n",
        "\n",
        "# Create plots directory\n",
        "os.makedirs(\"plots\", exist_ok=True)\n",
        "\n",
        "\n",
        "# Step 2.2: Data Visualization\n",
        "\n",
        "print(\"\\n--- Step 2.2: Data Visualization ---\")\n",
        "print(\"Visualizing feature distributions and relationships.\")\n",
        "\n",
        "# 3D Scatter Plot – X, Y, Z colored by Step\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "scatter = ax.scatter(df['X'], df['Y'], df['Z'], c=y_enc, cmap='tab20', s=60)\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "plt.title(\"3D Scatter Plot of Coordinates by Step\")\n",
        "legend1 = ax.legend(*scatter.legend_elements(), title=\"Step\")\n",
        "ax.add_artist(legend1)\n",
        "plt.savefig(\"plots/3D_scatter_steps.png\")\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "# Boxplots for each feature per Step\n",
        "for col in features:\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.boxplot(x='Step', y=col, data=df)\n",
        "    plt.title(f\"Boxplot of {col} by Step\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.savefig(f\"plots/boxplot_{col}.png\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "# Histograms for feature distributions\n",
        "df[features].hist(figsize=(8,6), bins=15)\n",
        "plt.suptitle(\"Feature Histograms\")\n",
        "plt.savefig(\"plots/feature_histograms.png\")\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "print(\"2.2 plots.  Boxplots used to help identify outliers, spread, and clustering. 3D scatter helps with visualizing separability between the steps.\")\n",
        "\n",
        "\n",
        "# Step 2.3: Correlation Analysis\n",
        "\n",
        "print(\"\\n--- Step 2.3: Correlation Analysis ---\")\n",
        "corr = df.corr(method='pearson')\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
        "plt.title(\"Feature Correlation Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"plots/correlation_matrix.png\")\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "for f in features:\n",
        "    print(f\"Correlation between {f} and Step: {corr.loc[f, target]:.4f}\")\n",
        "print(\"Pearson correlation indicates how strongly each feature is linearly related to the target.\")\n",
        "\n",
        "# Step 2.4: Classification Model Development\n",
        "\n",
        "print(\"\\n--- Step 2.4: Classification Model Development ---\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, stratify=y_enc, random_state=42)\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "def evaluate_model(name, estimator, params, randomized=False):\n",
        "    \"\"\"Trains, tunes, evaluates a model, prints metrics and saves confusion matrix\"\"\"\n",
        "    if randomized:\n",
        "        search = RandomizedSearchCV(estimator, params, cv=cv, n_iter=5, n_jobs=-1, scoring='f1_macro', random_state=42)\n",
        "    else:\n",
        "        search = GridSearchCV(estimator, params, cv=cv, n_jobs=-1, scoring='f1_macro')\n",
        "    search.fit(X_train, y_train)\n",
        "    best = search.best_estimator_\n",
        "    y_pred = best.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"\\n{name} Results:\")\n",
        "    print(f\"Best Params: {search.best_params_}\")\n",
        "    print(f\"Accuracy={acc:.4f}, Precision_macro={prec:.4f}, F1_macro={f1:.4f}\")\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(cm, display_labels=le.classes_)\n",
        "    disp.plot(cmap='Blues')\n",
        "    plt.title(f\"Confusion Matrix - {name}\")\n",
        "    plt.savefig(f\"plots/confmat_{name}.png\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    return best, f1\n",
        "\n",
        "# Define models and hyperparameters\n",
        "rf_pipe = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", RandomForestClassifier(random_state=42))])\n",
        "rf_params = {\"clf__n_estimators\": [50, 100], \"clf__max_depth\": [None, 10, 20]}\n",
        "\n",
        "svc_pipe = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", SVC(random_state=42))])\n",
        "svc_params = {\"clf__C\": [0.1, 1, 10], \"clf__kernel\": [\"rbf\", \"linear\"]}\n",
        "\n",
        "knn_pipe = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", KNeighborsClassifier())])\n",
        "knn_params = {\"clf__n_neighbors\": [3,5,7], \"clf__weights\": [\"uniform\",\"distance\"]}\n",
        "\n",
        "gb_params = {\"n_estimators\": [50,100,150], \"max_depth\": [2,3,4], \"learning_rate\": [0.01,0.05,0.1]}\n",
        "\n",
        "# Train & evaluate\n",
        "models = {}\n",
        "models[\"RandomForest\"], _ = evaluate_model(\"RandomForest\", rf_pipe, rf_params)\n",
        "models[\"SVC\"], _ = evaluate_model(\"SVC\", svc_pipe, svc_params)\n",
        "models[\"KNN\"], _ = evaluate_model(\"KNN\", knn_pipe, knn_params)\n",
        "models[\"GradientBoosting\"], _ = evaluate_model(\"GradientBoosting\", GradientBoostingClassifier(random_state=42), gb_params, randomized=True)\n",
        "\n",
        "print(\"Models trained. GridSearchCV finds best hyperparameters for RF, SVC, KNN. RandomizedSearchCV efficiently searches GB hyperparameters.\")\n",
        "\n",
        "\n",
        "# Step 2.6: Stacked Model Performance\n",
        "\n",
        "print(\"\\n--- Step 2.6: Stacked Model Performance ---\")\n",
        "estimators = [(\"rf\", models[\"RandomForest\"]), (\"svc\", models[\"SVC\"])]\n",
        "stacked = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(max_iter=1000))\n",
        "stacked.fit(X_train, y_train)\n",
        "\n",
        "y_pred_stacked = stacked.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred_stacked)\n",
        "prec = precision_score(y_test, y_pred_stacked, average='macro', zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred_stacked, average='macro', zero_division=0)\n",
        "print(f\"Stacked Model Performance: Accuracy={acc:.4f}, Precision_macro={prec:.4f}, F1_macro={f1:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_stacked)\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=le.classes_)\n",
        "disp.plot(cmap='Purples')\n",
        "plt.title(\"Confusion Matrix - Stacked Model\")\n",
        "plt.savefig(\"plots/confmat_stacked.png\")\n",
        "plt.show()\n",
        "plt.close()\n",
        "print(\"Stacked model combines RF + SVC to leverage complementary strengths.\")\n",
        "\n",
        "\n",
        "# Step 2.7: Save Model & Predict New Coordinates\n",
        "\n",
        "dump({\"model\": stacked, \"label_encoder\": le, \"features\": features}, \"selected_model.joblib\")\n",
        "print(\"\\nStacked model saved as 'selected_model.joblib'\")\n",
        "\n",
        "new_coords = np.array([\n",
        "    [9.375,3.0625,1.51],\n",
        "    [6.995,5.125,0.3875],\n",
        "    [0,3.0625,1.93],\n",
        "    [9.4,3,1.8],\n",
        "    [9.4,3,1.3]\n",
        "])\n",
        "preds = stacked.predict(new_coords)\n",
        "decoded_preds = le.inverse_transform(preds)\n",
        "\n",
        "print(\"\\nPredictions for new coordinates:\")\n",
        "for coord, label in zip(new_coords, decoded_preds):\n",
        "    print(f\"{coord} -> Step {label}\")\n"
      ],
      "metadata": {
        "id": "1A-gw8zalmDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9m9cEBG7Z6IS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}